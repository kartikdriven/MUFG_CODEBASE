{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhU0AWDvPht75xbuZAqWq2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Convolutional Neural Networks (CNNs)\n","\n","---\n","\n","## Introduction\n","\n","A **Convolutional Neural Network (CNN)** is a type of deep learning model primarily used for **image processing**, **computer vision**, and other grid-like data tasks. CNNs automatically and adaptively learn **spatial hierarchies of features** through convolution operations, making them highly effective for tasks like image classification, object detection, and segmentation.\n","\n","---\n","\n","## Key Components of CNNs\n","\n","### 1. Convolutional Layer (Filters/Kernels)\n","- **Purpose:** Automatically extract features from input data (e.g., edges, textures, shapes in images).  \n","- **Operation:** A small matrix called a **filter** (or **kernel**) slides over the input image to compute **feature maps** via element-wise multiplication and summation.  \n","- **Mathematical Representation:**  \n","\n","\\[\n","S(i,j) = (X * K)(i,j) = \\sum_m \\sum_n X(i+m, j+n) \\cdot K(m,n)\n","\\]\n","\n","Where:  \n","- \\(X\\) = input image  \n","- \\(K\\) = filter/kernel  \n","- \\(S\\) = resulting feature map  \n","\n","- **Filters learn** important patterns during training. Multiple filters capture multiple types of features.\n","\n","---\n","\n","### 2. Activation Functions\n","- Introduce **non-linearity** to allow the network to learn complex patterns.  \n","- Common activations in CNNs:\n","  - **ReLU (Rectified Linear Unit):** \\(f(x) = \\max(0, x)\\)\n","  - **Leaky ReLU:** Prevents dead neurons.\n","  \n","---\n","\n","### 3. Pooling Layer\n","- **Purpose:** Reduce spatial dimensions of feature maps, lowering computation and controlling overfitting.  \n","- **Types:**\n","  - **Max Pooling:** Takes the maximum value in a window.\n","  - **Average Pooling:** Takes the average value in a window.\n","- Example: A 2x2 max pooling reduces a 4x4 feature map to 2x2.\n","\n","---\n","\n","### 4. Fully Connected Layer\n","- After convolution and pooling, feature maps are **flattened** into a 1D vector.  \n","- Fully connected layers perform **high-level reasoning** and map features to final outputs (e.g., class scores).\n","\n","---\n","\n","### 5. Dropout Layer (Optional)\n","- Randomly **ignores neurons** during training to prevent overfitting and improve generalization.\n","\n","---\n","\n","## CNN Architecture Summary\n","\n","A typical CNN architecture includes:\n","\n","1. **Input Layer:** Raw image data.  \n","2. **Convolution + Activation:** Extracts local features.  \n","3. **Pooling Layer:** Downsamples feature maps.  \n","4. **(Repeat Conv + Pooling):** To learn hierarchical features.  \n","5. **Flatten Layer:** Converts 2D feature maps to 1D vector.  \n","6. **Fully Connected Layers:** For classification or regression.  \n","7. **Output Layer:** Produces predictions (softmax for classification, linear for regression).\n","\n","---\n","\n","## Applications of CNNs\n","\n","- Image Classification (e.g., MNIST, CIFAR-10)  \n","- Object Detection (e.g., YOLO, Faster R-CNN)  \n","- Image Segmentation (e.g., U-Net)  \n","- Facial Recognition  \n","- Video Analysis  \n","- Medical Imaging (e.g., tumor detection)\n"],"metadata":{"id":"JwR2bk9unRvS"}},{"cell_type":"code","source":["# ==============================\n","# Convolutional Neural Network (CNN) Example with TensorFlow/Keras\n","# ==============================\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","\n","# 1. Load dataset (MNIST)\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# 2. Preprocess data\n","# Reshape to add channel dimension and normalize\n","X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n","X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n","\n","# One-hot encode labels\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# 3. Build CNN model\n","model = Sequential([\n","    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n","    MaxPooling2D(pool_size=(2,2)),\n","    Conv2D(64, kernel_size=(3,3), activation='relu'),\n","    MaxPooling2D(pool_size=(2,2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","# 4. Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 5. Train the model\n","history = model.fit(\n","    X_train, y_train,\n","    validation_split=0.2,\n","    epochs=10,\n","    batch_size=64,\n","    verbose=1\n",")\n","\n","# 6. Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"\\nTest Loss: {loss:.4f}\")\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","# 7. Plot training history\n","plt.figure(figsize=(10,5))\n","plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('CNN Accuracy over Epochs')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","plt.figure(figsize=(10,5))\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('CNN Loss over Epochs')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"mmhlqllzpI4i","outputId":"977e8da2-83c6-44eb-af65-17f0bf257289","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m282/750\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.7810 - loss: 0.6976"]}]}]}